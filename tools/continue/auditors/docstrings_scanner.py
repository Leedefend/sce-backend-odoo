#!/usr/bin/env python3
"""
Continue CLI æ–‡æ¡£å­—ç¬¦ä¸²å®¡è®¡å™¨
æ‰«ææŒ‡å®šæ¨¡å—çš„Pythonæ–‡ä»¶ï¼Œåˆ†æžæ–‡æ¡£å­—ç¬¦ä¸²è¦†ç›–çŽ‡

è¾“å‡ºï¼š
- artifacts/continue/audit_docstrings.md (äººè¯»æŠ¥å‘Š)
- artifacts/continue/audit_docstrings.json (æœºå™¨æ•°æ®)
"""

import os
import sys
import json
import ast
import traceback
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple, Any, Optional
import subprocess

class DocstringsScanner:
    """æ–‡æ¡£å­—ç¬¦ä¸²æ‰«æå™¨"""
    
    def __init__(self, module_path: str, output_dir: str = "artifacts/continue"):
        self.module_path = Path(module_path).resolve()
        self.output_dir = Path(output_dir).resolve()
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # æŽ’é™¤ç›®å½•åˆ—è¡¨
        self.exclude_dirs = {
            "__pycache__",
            ".venv",
            "venv",
            "env",
            ".env",
            "node_modules",
            "migrations",
            "runtime",
            "artifacts",
            "tmp",
            ".tmp",
            "temp",
            ".cache",
            ".state",
            ".codex_home",
            ".config"
        }
        
        # æ‰«æç»“æžœ
        self.scan_results = {
            "metadata": {},
            "statistics": {},
            "files": [],
            "errors": [],
            "missing_docstrings": [],
            "by_category": {}
        }
    
    def collect_metadata(self):
        """æ”¶é›†å…ƒæ•°æ®"""
        self.scan_results["metadata"] = {
            "scan_time": datetime.now().isoformat(),
            "module_path": str(self.module_path),
            "output_dir": str(self.output_dir),
            "git_info": self.get_git_info(),
            "python_version": sys.version,
            "scanner_version": "v0.1.0"
        }
    
    def get_git_info(self) -> Dict[str, str]:
        """èŽ·å–Gitä¿¡æ¯"""
        try:
            commit_hash = subprocess.check_output(
                ["git", "rev-parse", "HEAD"],
                cwd=self.module_path.parent,
                text=True
            ).strip()
            
            branch = subprocess.check_output(
                ["git", "rev-parse", "--abbrev-ref", "HEAD"],
                cwd=self.module_path.parent,
                text=True
            ).strip()
            
            return {
                "commit": commit_hash,
                "branch": branch,
                "repo_root": str(self.module_path.parent)
            }
        except Exception as e:
            return {"error": str(e)}
    
    def should_exclude_file(self, filepath: Path) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥æŽ’é™¤æ–‡ä»¶"""
        # æ£€æŸ¥æŽ’é™¤ç›®å½•
        for part in filepath.parts:
            if part in self.exclude_dirs:
                return True
        
        # æ£€æŸ¥æ–‡ä»¶å
        if filepath.name.startswith('.'):
            return True
        
        return False
    
    def is_dunder_method(self, name: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦æ˜¯é­”æœ¯æ–¹æ³•ï¼ˆdunder methodï¼‰"""
        return name.startswith('__') and name.endswith('__')
    
    def scan_file(self, filepath: Path) -> Dict[str, Any]:
        """æ‰«æå•ä¸ªPythonæ–‡ä»¶"""
        try:
            # æ£€æŸ¥æ–‡ä»¶ç¼–ç 
            try:
                with open(filepath, 'r', encoding='utf-8') as f:
                    content = f.read()
            except UnicodeDecodeError:
                # å°è¯•å…¶ä»–ç¼–ç 
                try:
                    with open(filepath, 'r', encoding='latin-1') as f:
                        content = f.read()
                except Exception as e:
                    raise UnicodeDecodeError(f"æ— æ³•è§£ç æ–‡ä»¶ {filepath}: {e}")
            
            tree = ast.parse(content, filename=str(filepath))
            
            # ç»Ÿè®¡ä¿¡æ¯
            stats = {
                "file": str(filepath.relative_to(self.module_path)),
                "total_lines": len(content.splitlines()),
                "classes": [],
                "functions": [],
                "methods": [],
                "has_module_docstring": ast.get_docstring(tree) is not None,
                "qualified_names": []  # ç”¨äºŽæŽ’åº
            }
            
            # ä½¿ç”¨è‡ªå®šä¹‰è®¿é—®å™¨æ¥å»ºç«‹çˆ¶å­å…³ç³»
            class NodeVisitor(ast.NodeVisitor):
                def __init__(self, stats, is_dunder_method):
                    self.stats = stats
                    self.is_dunder_method = is_dunder_method
                    self.current_class = None
                
                def visit_ClassDef(self, node):
                    # ä¿å­˜å½“å‰ç±»
                    old_class = self.current_class
                    self.current_class = node.name
                    
                    class_info = {
                        "name": node.name,
                        "line": node.lineno,
                        "has_docstring": ast.get_docstring(node) is not None,
                        "methods": []
                    }
                    
                    # æ£€æŸ¥ç±»æ–¹æ³•
                    for item in node.body:
                        if isinstance(item, ast.FunctionDef):
                            # è·³è¿‡é­”æœ¯æ–¹æ³•
                            if self.is_dunder_method(item.name):
                                continue
                                
                            method_info = {
                                "name": item.name,
                                "line": item.lineno,
                                "has_docstring": ast.get_docstring(item) is not None
                            }
                            class_info["methods"].append(method_info)
                            self.stats["methods"].append(method_info)
                    
                    self.stats["classes"].append(class_info)
                    self.stats["qualified_names"].append(f"{self.stats['file']}:{node.lineno}:class:{node.name}")
                    
                    # ç»§ç»­éåŽ†å­èŠ‚ç‚¹
                    self.generic_visit(node)
                    self.current_class = old_class
                
                def visit_FunctionDef(self, node):
                    # è·³è¿‡é­”æœ¯æ–¹æ³•
                    if self.is_dunder_method(node.name):
                        return
                    
                    # å¦‚æžœæ˜¯ç±»æ–¹æ³•ï¼Œå·²ç»åœ¨visit_ClassDefä¸­å¤„ç†
                    if self.current_class is not None:
                        return
                    
                    # é¡¶å±‚å‡½æ•°
                    func_info = {
                        "name": node.name,
                        "line": node.lineno,
                        "has_docstring": ast.get_docstring(node) is not None
                    }
                    self.stats["functions"].append(func_info)
                    self.stats["qualified_names"].append(f"{self.stats['file']}:{node.lineno}:function:{node.name}")
                    
                    self.generic_visit(node)
            
            visitor = NodeVisitor(stats, self.is_dunder_method)
            visitor.visit(tree)
            
            return stats
            
        except SyntaxError as e:
            error_msg = f"è¯­æ³•é”™è¯¯: {e.msg} (è¡Œ{e.lineno}, åˆ—{e.offset})"
            return {
                "file": str(filepath.relative_to(self.module_path)),
                "error": error_msg,
                "error_type": "syntax_error"
            }
        except UnicodeDecodeError as e:
            return {
                "file": str(filepath.relative_to(self.module_path)),
                "error": str(e),
                "error_type": "encoding_error"
            }
        except Exception as e:
            return {
                "file": str(filepath.relative_to(self.module_path)),
                "error": f"{type(e).__name__}: {str(e)}",
                "error_type": "other_error"
            }
    
    def scan_module(self):
        """æ‰«ææ•´ä¸ªæ¨¡å—"""
        python_files = []
        for filepath in self.module_path.rglob("*.py"):
            if not self.should_exclude_file(filepath):
                python_files.append(filepath)
        
        print(f"æ‰«ææ¨¡å—: {self.module_path}")
        print(f"æ‰¾åˆ° {len(python_files)} ä¸ªPythonæ–‡ä»¶ï¼ˆå·²æŽ’é™¤ {len(list(self.module_path.rglob('*.py'))) - len(python_files)} ä¸ªæŽ’é™¤æ–‡ä»¶ï¼‰")
        
        for i, filepath in enumerate(python_files, 1):
            print(f"  [{i}/{len(python_files)}] æ‰«æ: {filepath.relative_to(self.module_path)}")
            file_stats = self.scan_file(filepath)
            
            if "error" in file_stats:
                self.scan_results["errors"].append(file_stats)
                print(f"    âš  é”™è¯¯: {file_stats['error']}")
            else:
                self.scan_results["files"].append(file_stats)
        
        self.calculate_statistics()
    
    def calculate_statistics(self):
        """è®¡ç®—ç»Ÿè®¡ä¿¡æ¯"""
        total_files = len(self.scan_results["files"])
        total_errors = len(self.scan_results["errors"])
        total_classes = 0
        total_functions = 0
        total_methods = 0
        classes_with_docstrings = 0
        functions_with_docstrings = 0
        methods_with_docstrings = 0
        
        missing_items = []
        
        for file_stats in self.scan_results["files"]:
            # ç»Ÿè®¡ç±»
            for class_info in file_stats["classes"]:
                total_classes += 1
                if class_info["has_docstring"]:
                    classes_with_docstrings += 1
                else:
                    missing_items.append({
                        "type": "class",
                        "file": file_stats["file"],
                        "name": class_info["name"],
                        "line": class_info["line"],
                        "qualified_name": f"{file_stats['file']}:{class_info['line']}:class:{class_info['name']}"
                    })
                
                # ç»Ÿè®¡æ–¹æ³•
                for method_info in class_info["methods"]:
                    total_methods += 1
                    if method_info["has_docstring"]:
                        methods_with_docstrings += 1
                    else:
                        missing_items.append({
                            "type": "method",
                            "file": file_stats["file"],
                            "class": class_info["name"],
                            "name": method_info["name"],
                            "line": method_info["line"],
                            "qualified_name": f"{file_stats['file']}:{method_info['line']}:method:{class_info['name']}.{method_info['name']}"
                        })
            
            # ç»Ÿè®¡å‡½æ•°
            for func_info in file_stats["functions"]:
                total_functions += 1
                if func_info["has_docstring"]:
                    functions_with_docstrings += 1
                else:
                    missing_items.append({
                        "type": "function",
                        "file": file_stats["file"],
                        "name": func_info["name"],
                        "line": func_info["line"],
                        "qualified_name": f"{file_stats['file']}:{func_info['line']}:function:{func_info['name']}"
                    })
        
        # è®¡ç®—è¦†ç›–çŽ‡
        class_coverage = (classes_with_docstrings / total_classes * 100) if total_classes > 0 else 100
        function_coverage = (functions_with_docstrings / total_functions * 100) if total_functions > 0 else 100
        method_coverage = (methods_with_docstrings / total_methods * 100) if total_methods > 0 else 100
        
        overall_total = total_classes + total_functions + total_methods
        overall_with_docstrings = classes_with_docstrings + functions_with_docstrings + methods_with_docstrings
        overall_coverage = (overall_with_docstrings / overall_total * 100) if overall_total > 0 else 100
        
        # æŒ‰qualified_nameæŽ’åºï¼Œç¡®ä¿è¾“å‡ºç¨³å®š
        missing_items.sort(key=lambda x: x["qualified_name"])
        
        self.scan_results["statistics"] = {
            "total_files": total_files,
            "total_errors": total_errors,
            "total_classes": total_classes,
            "total_functions": total_functions,
            "total_methods": total_methods,
            "classes_with_docstrings": classes_with_docstrings,
            "functions_with_docstrings": functions_with_docstrings,
            "methods_with_docstrings": methods_with_docstrings,
            "class_coverage_percent": round(class_coverage, 2),
            "function_coverage_percent": round(function_coverage, 2),
            "method_coverage_percent": round(method_coverage, 2),
            "overall_coverage_percent": round(overall_coverage, 2),
            "missing_count": len(missing_items),
            "statistics_calculation": {
                "denominator_excludes": [
                    "dunder_methods (__init__, __str__, etc.)",
                    "excluded_directories (__pycache__, migrations, etc.)",
                    "files_with_errors"
                ],
                "coverage_formula": "(items_with_docstrings / total_items * 100)",
                "item_types": ["class", "function", "method"]
            }
        }
        
        self.scan_results["missing_docstrings"] = missing_items
        
        # æŒ‰ç±»åˆ«åˆ†ç»„
        self.scan_results["by_category"] = {
            "controllers": self.filter_by_category("controllers"),
            "models": self.filter_by_category("models"),
            "services": self.filter_by_category("services"),
            "other": self.filter_by_category("other")
        }
    
    def filter_by_category(self, category: str) -> List[Dict]:
        """æŒ‰ç±»åˆ«è¿‡æ»¤ç¼ºå¤±çš„æ–‡æ¡£å­—ç¬¦ä¸²"""
        if category == "controllers":
            return [item for item in self.scan_results["missing_docstrings"] 
                   if "/controllers/" in item["file"]]
        elif category == "models":
            return [item for item in self.scan_results["missing_docstrings"] 
                   if "/models/" in item["file"]]
        elif category == "services":
            return [item for item in self.scan_results["missing_docstrings"] 
                   if "/services/" in item["file"] or "/wizards/" in item["file"]]
        else:
            return [item for item in self.scan_results["missing_docstrings"] 
                   if not any(x in item["file"] for x in ["/controllers/", "/models/", "/services/", "/wizards/"])]
    
    def generate_json_report(self):
        """ç”ŸæˆJSONæŠ¥å‘Š"""
        json_path = self.output_dir / "audit_docstrings.json"
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(self.scan_results, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… JSONæŠ¥å‘Šå·²ç”Ÿæˆ: {json_path}")
        return json_path
    
    def generate_markdown_report(self):
        """ç”ŸæˆMarkdownæŠ¥å‘Š"""
        md_path = self.output_dir / "audit_docstrings.md"
        
        stats = self.scan_results["statistics"]
        metadata = self.scan_results["metadata"]
        errors = self.scan_results["errors"]
        
        with open(md_path, 'w', encoding='utf-8') as f:
            f.write(f"# æ–‡æ¡£å­—ç¬¦ä¸²å®¡è®¡æŠ¥å‘Š\n\n")
            f.write(f"**æ‰«ææ—¶é—´**: {metadata['scan_time']}\n")
            f.write(f"**æ‰«ææ¨¡å—**: `{metadata['module_path']}`\n")
            f.write(f"**Gitæäº¤**: `{metadata['git_info'].get('commit', 'N/A')}`\n")
            f.write(f"**Gitåˆ†æ”¯**: `{metadata['git_info'].get('branch', 'N/A')}`\n")
            f.write(f"**Gitä»“åº“**: `{metadata['git_info'].get('repo_root', 'N/A')}`\n")
            f.write(f"**Pythonç‰ˆæœ¬**: {metadata['python_version'].split()[0]}\n")
            f.write(f"**æ‰«æå™¨ç‰ˆæœ¬**: {metadata['scanner_version']}\n\n")
            
            f.write(f"## ðŸ“Š ç»Ÿè®¡æ¦‚è§ˆ\n\n")
            f.write(f"| æŒ‡æ ‡ | æ•°é‡ | è¦†ç›–çŽ‡ |\n")
            f.write(f"|------|------|--------|\n")
            f.write(f"| æˆåŠŸæ‰«ææ–‡ä»¶ | {stats['total_files']} | - |\n")
            f.write(f"| é”™è¯¯æ–‡ä»¶ | {stats['total_errors']} | - |\n")
            f.write(f"| ç±»æ€»æ•° | {stats['total_classes']} | {stats['class_coverage_percent']}% |\n")
            f.write(f"| å‡½æ•°æ€»æ•° | {stats['total_functions']} | {stats['function_coverage_percent']}% |\n")
            f.write(f"| æ–¹æ³•æ€»æ•° | {stats['total_methods']} | {stats['method_coverage_percent']}% |\n")
            f.write(f"| **æ€»è®¡** | **{stats['total_classes'] + stats['total_functions'] + stats['total_methods']}** | **{stats['overall_coverage_percent']}%** |\n\n")
            
            if errors:
                f.write(f"## âš ï¸ æ‰«æé”™è¯¯ ({len(errors)}ä¸ªæ–‡ä»¶)\n\n")
                f.write(f"| æ–‡ä»¶ | é”™è¯¯ç±»åž‹ | é”™è¯¯ä¿¡æ¯ |\n")
                f.write(f"|------|----------|----------|\n")
                for error in errors[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ªé”™è¯¯
                    error_type = error.get('error_type', 'unknown')
                    f.write(f"| `{error['file']}` | {error_type} | `{error['error'][:100]}...` |\n")
                if len(errors) > 10:
                    f.write(f"| ... | è¿˜æœ‰ {len(errors) - 10} ä¸ªé”™è¯¯æœªæ˜¾ç¤º | ... |\n")
                f.write("\n")
            
            f.write(f"## âš ï¸ ç¼ºå¤±æ–‡æ¡£å­—ç¬¦ä¸² ({stats['missing_count']}ä¸ª)\n\n")
            
            # æŒ‰ç±»åˆ«æ˜¾ç¤º
            for category_name, items in self.scan_results["by_category"].items():
                if items:
                    f.write(f"### {category_name.upper()} ({len(items)}ä¸ª)\n\n")
                    f.write(f"| ç±»åž‹ | æ–‡ä»¶ | åç§° | è¡Œå· |\n")
                    f.write(f"|------|------|------|------|\n")
                    for item in items[:20]:  # åªæ˜¾ç¤ºå‰20ä¸ª
                        if item["type"] == "method":
                            name = f"{item['class']}.{item['name']}"
                        else:
                            name = item["name"]
                        f.write(f"| {item['type']} | `{item['file']}` | `{name}` | {item['line']} |\n")
                    
                    if len(items) > 20:
                        f.write(f"| ... | è¿˜æœ‰ {len(items) - 20} ä¸ªæœªæ˜¾ç¤º | ... | ... |\n")
                    f.write("\n")
            
            f.write(f"## ðŸ“‹ å®¡è®¡è§„åˆ™è¯´æ˜Ž\n\n")
            f.write(f"### ç»Ÿè®¡å£å¾„\n")
            f.write(f"1. **è¦†ç›–çŽ‡å…¬å¼**: `(æœ‰æ–‡æ¡£å­—ç¬¦ä¸²çš„é¡¹ / æ€»é¡¹æ•° * 100)`\n")
            f.write(f"2. **é¡¹ç±»åž‹**: ç±»ã€å‡½æ•°ã€æ–¹æ³•\n")
            f.write(f"3. **æŽ’é™¤é¡¹**:\n")
            for exclude in stats.get('statistics_calculation', {}).get('denominator_excludes', []):
                f.write(f"   - {exclude}\n")
            f.write(f"\n### æ‰«æè§„åˆ™\n")
            f.write(f"1. **å®¡è®¡èŒƒå›´**: Pythonç±»ã€å‡½æ•°ã€æ–¹æ³•\n")
            f.write(f"2. **æ–‡æ¡£å­—ç¬¦ä¸²åˆ¤å®š**: ä½¿ç”¨Pythonæ ‡å‡†åº“ `ast.get_docstring()`\n")
            f.write(f"3. **æŽ’é™¤é­”æœ¯æ–¹æ³•**: `__init__`, `__str__`, `__repr__` ç­‰\n")
            f.write(f"4. **æŽ’é™¤ç›®å½•**: `__pycache__`, `migrations`, `runtime`, `artifacts` ç­‰\n")
            f.write(f"5. **ç±»åˆ«åˆ’åˆ†**:\n")
            f.write(f"   - `controllers`: `/controllers/` ç›®å½•ä¸‹çš„æ–‡ä»¶\n")
            f.write(f"   - `models`: `/models/` ç›®å½•ä¸‹çš„æ–‡ä»¶\n")
            f.write(f"   - `services`: `/services/` æˆ– `/wizards/` ç›®å½•ä¸‹çš„æ–‡ä»¶\n")
            f.write(f"   - `other`: å…¶ä»–ç›®å½•ä¸‹çš„æ–‡ä»¶\n\n")
            
            f.write(f"## ðŸ”§ å¦‚ä½•ä¿®å¤\n\n")
            f.write(f"1. **ä¸ºç¼ºå¤±æ–‡æ¡£å­—ç¬¦ä¸²çš„ç±»/å‡½æ•°/æ–¹æ³•æ·»åŠ docstring**\n")
            f.write(f"2. **æ ‡å‡†æ ¼å¼**: `\"\"\"ç®€è¦æè¿°ã€‚\"\"\"`\n")
            f.write(f"3. **å¤æ‚æ–¹æ³•åº”åŒ…å«**: å‚æ•°è¯´æ˜Žã€è¿”å›žå€¼è¯´æ˜Žã€ç¤ºä¾‹ç­‰\n")
            f.write(f"4. **é‡æ–°è¿è¡Œå®¡è®¡**: `make cn.audit.docstrings`\n")
            f.write(f"5. **æµ‹è¯•å®¡è®¡**: `make cn.audit.docstrings.test` (ä»…æ‰«æcontrollersç›®å½•)\n\n")
            
            f.write(f"## ðŸ”— ç›¸å…³é“¾æŽ¥\n\n")
            f.write(f"- [Pythonæ–‡æ¡£å­—ç¬¦ä¸²è§„èŒƒ (PEP 257)](https://www.python.org/dev/peps/pep-0257/)\n")
            f.write(f"- [Googleé£Žæ ¼æ–‡æ¡£å­—ç¬¦ä¸²æŒ‡å—](https://google.github.io/styleguide/pyguide.html#38-comments-and-docstrings)\n")
            f.write(f"- [Continue CLIé›†æˆæ–‡æ¡£](docs/devtools/continue/README.md)\n")
        
        print(f"âœ… MarkdownæŠ¥å‘Šå·²ç”Ÿæˆ: {md_path}")
        return md_path
    
    def run(self):
        """è¿è¡Œæ‰«æå™¨"""
        print("=" * 60)
        print("Continue CLI æ–‡æ¡£å­—ç¬¦ä¸²å®¡è®¡å™¨")
        print("=" * 60)
        
        self.collect_metadata()
        self.scan_module()
        
        json_path = self.generate_json_report()
        md_path = self.generate_markdown_report()
        
        print("=" * 60)
        print("âœ… å®¡è®¡å®Œæˆ!")
        print(f"   æŠ¥å‘Šæ–‡ä»¶: {md_path}")
        print(f"   æ•°æ®æ–‡ä»¶: {json_path}")
        print("=" * 60)


def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) > 1:
        module_path = sys.argv[1]
    else:
        module_path = "addons/smart_construction_core"
    
    if len(sys.argv) > 2:
        output_dir = sys.argv[2]
    else:
        output_dir = "artifacts/continue"
    
    scanner = DocstringsScanner(module_path, output_dir)
    scanner.run()


if __name__ == "__main__":
    main()